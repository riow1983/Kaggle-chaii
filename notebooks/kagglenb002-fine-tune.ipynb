{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"USE_PIPELINE = False\nMODEL_PATH = \"../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2\" #\"../input/localnb001-export-transformers\"\nMODEL_NAME_FINETUNED = \"model_deepset_xlm_roberta_large_squad2\" #\"model\"\nbatch_size = 2 # it's only used when USE_PIPELINE = False\n\nfrom transformers import BertTokenizerFast, XLMRobertaTokenizerFast\nfrom transformers import BertForQuestionAnswering, XLMRobertaForQuestionAnswering\n\nMODEL_PATH_TO_OBJECT = {\n    \"../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2\": [XLMRobertaTokenizerFast, XLMRobertaForQuestionAnswering],\n    \"../input/localnb001-export-transformers\": [BertTokenizerFast, BertForQuestionAnswering]\n}\n\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#from statistics import mode\nimport collections\nfrom tqdm import tqdm\nimport re\nfrom transformers import pipeline\nimport torch\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-27T02:16:08.181494Z","iopub.execute_input":"2021-09-27T02:16:08.181907Z","iopub.status.idle":"2021-09-27T02:16:15.692351Z","shell.execute_reply.started":"2021-09-27T02:16:08.18182Z","shell.execute_reply":"2021-09-27T02:16:15.69151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers import pipeline\n# if DISABLE_INTERNET:\n#     model_path = \"../input/localnb001-export-transformers\"\n#     model = pipeline('question-answering', model=model_path, tokenizer=model_path, device=0)\n# else:\n#     model = pipeline('question-answering', model='bert-base-multilingual-cased', device=0)\n\n\ntokenizer = MODEL_PATH_TO_OBJECT[MODEL_PATH][0].from_pretrained(MODEL_PATH)\nmodel = MODEL_PATH_TO_OBJECT[MODEL_PATH][1].from_pretrained(MODEL_PATH)\n\n\n# Load model weights and optimizer state\noutput_model = f\"../input/localnb002-fine-tune/{MODEL_NAME_FINETUNED}.pth\"\ncheckpoint = torch.load(output_model, map_location='cpu')\nmodel.load_state_dict(checkpoint['model_state_dict'])\n\nif USE_PIPELINE:\n    #model = pipeline('question-answering', model=model_path, tokenizer=model_path, device=0)\n    model = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=0)\nelse:\n    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n    model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T02:16:15.693846Z","iopub.execute_input":"2021-09-27T02:16:15.694177Z","iopub.status.idle":"2021-09-27T02:17:33.461331Z","shell.execute_reply.started":"2021-09-27T02:16:15.694143Z","shell.execute_reply":"2021-09-27T02:17:33.460299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"../input/chaii-hindi-and-tamil-question-answering/test.csv\")\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T02:17:33.463207Z","iopub.execute_input":"2021-09-27T02:17:33.46358Z","iopub.status.idle":"2021-09-27T02:17:33.514007Z","shell.execute_reply.started":"2021-09-27T02:17:33.463541Z","shell.execute_reply":"2021-09-27T02:17:33.513127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_mode(x):\n    \"\"\"\n    Args:\n        x: List[str]\n    Returns:\n        str\n    \"\"\"\n    # drop \"\" from the list\n    x = [el for el in x if el!=\"\"]\n    if len(x)==0:\n        x = [\"\"]\n    #return mode(x)\n    return collections.Counter(x).most_common()[0][0]","metadata":{"execution":{"iopub.status.busy":"2021-09-27T02:17:33.515737Z","iopub.execute_input":"2021-09-27T02:17:33.516084Z","iopub.status.idle":"2021-09-27T02:17:33.521207Z","shell.execute_reply.started":"2021-09-27T02:17:33.51605Z","shell.execute_reply":"2021-09-27T02:17:33.520302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_fn_pipeline():\n    test[\"PredictionString\"] = \"\"\n    tqdm_df_itertuples = tqdm(test.itertuples(), total=len(test))\n    for row in tqdm_df_itertuples:\n        i = row[0]\n        context = row[2]\n        question = row[3]\n        \n        output = model(question=question, context=context)\n        pred = output[\"answer\"]\n        \n        test.loc[i, \"PredictionString\"] = pred\n        \n    return test","metadata":{"execution":{"iopub.status.busy":"2021-09-27T02:17:33.52279Z","iopub.execute_input":"2021-09-27T02:17:33.523149Z","iopub.status.idle":"2021-09-27T02:17:33.530498Z","shell.execute_reply.started":"2021-09-27T02:17:33.523113Z","shell.execute_reply":"2021-09-27T02:17:33.529607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_fn_naive(test, verbose=False):\n    \"\"\"\n    Args:\n        test: pandas.DataFrame\n        verbose: bool\n    Returns:\n        test: pandas.DataFrame\n    \"\"\"\n    test[\"PredictionString\"] = \"\"\n    progress_bar = tqdm(range(len(test_dataloader)))\n    \n    for i, batch in enumerate(test_dataloader):\n        input_ids = batch['input_ids'].to(device)\n        # attention_mask = batch['attention_mask'].to(device)\n        with torch.no_grad():\n            outputs = model(input_ids)\n\n        answer_start_scores = outputs.start_logits\n        answer_end_scores = outputs.end_logits\n        # Get the most likely beginning of answer with the argmax of the score\n        answer_start = torch.argmax(answer_start_scores, dim=-1)\n        # Get the most likely end of answer with the argmax of the score\n        answer_end = torch.argmax(answer_end_scores, dim=-1)\n        \n        #### RIOW\n#         pred = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n#         test.loc[i, \"PredictionString\"] = pred\n        \n        if verbose:\n            print(\"input_ids.shape: \",input_ids.shape)\n            print(\"answer_start.shape: \", answer_start.shape)\n            print(\"answer_end.shape: \", answer_end.shape)\n            print()\n        \n        #for j in range(batch_size):\n        pred_answer_j_s = []\n        for j in range(len(batch)):\n            #if len(batch)>1:\n            if input_ids.shape[0]>1:\n                pred_answer_j = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[j][answer_start[j]:answer_end[j]]))\n            else:\n                pred_answer_j = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n            pred_answer_j_s.append(pred_answer_j)\n            #test.loc[i*batch_size+j, \"PredictionString\"] = pred_answer_j\n            if verbose:\n                print(\"pred_answer_j_s: \", pred_answer_j_s)\n                print(\"mode(pred_answer_j_s): \", custom_mode(pred_answer_j_s))\n                print()\n        \n        \n        test.loc[i*len(batch)+j, \"PredictionString\"] = custom_mode(pred_answer_j_s)\n        \n        progress_bar.update(1)\n        #### RIOWRIOW\n        \n    return test","metadata":{"execution":{"iopub.status.busy":"2021-09-27T02:17:33.532039Z","iopub.execute_input":"2021-09-27T02:17:33.53243Z","iopub.status.idle":"2021-09-27T02:17:33.544208Z","shell.execute_reply.started":"2021-09-27T02:17:33.532396Z","shell.execute_reply":"2021-09-27T02:17:33.543261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def test_fn(use_pipeline=False):\n#     test[\"PredictionString\"] = \"\"\n#     tqdm_df_itertuples = tqdm(test.itertuples(), total=len(test))\n#     for row in tqdm_df_itertuples:\n#         i = row[0]\n#         context = row[2]\n#         question = row[3]\n        \n#         if use_pipeline:\n#             output = model(question=question, context=context)\n#             pred = output[\"answer\"]\n#         else:\n#             inputs = tokenizer(question, \n#                                context, \n#                                add_special_tokens=True,\n#                                max_length=512,\n#                                padding=True, \n#                                truncation=True, \n#                                return_tensors=\"pt\")\n#             inputs.to(device)\n#             input_ids = inputs[\"input_ids\"].tolist()[0]\n#             outputs = model(**inputs)\n#             answer_start_scores = outputs.start_logits\n#             answer_end_scores = outputs.end_logits\n\n#             # Get the most likely beginning of answer with the argmax of the score\n#             answer_start = torch.argmax(answer_start_scores)\n#             # Get the most likely end of answer with the argmax of the score\n#             answer_end = torch.argmax(answer_end_scores) + 1\n\n#             pred = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n\n#         test.loc[i, \"PredictionString\"] = pred\n        \n#     return test","metadata":{"execution":{"iopub.status.busy":"2021-09-27T02:17:33.545697Z","iopub.execute_input":"2021-09-27T02:17:33.546066Z","iopub.status.idle":"2021-09-27T02:17:33.555459Z","shell.execute_reply.started":"2021-09-27T02:17:33.546031Z","shell.execute_reply":"2021-09-27T02:17:33.55452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### Functions for naive inference\n\n# Text cleansing for context\n\n#alphabets = \"([A-Za-z])\"\nalphabets = \"([\\u0900-\\u097F\\u0B80-\\u0BFF])\" # Hindi & Tamil\nprefixes = re.compile(\"(Mr|St|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|Mt)[.]\")\nsuffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\nstarters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\nacronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\nwebsites = re.compile(\"[.](co|net|org|io|gov|edu|us)\")\netal = re.compile(r\"(\\bet al)[.]\")\nurls = re.compile(\"(www)[.]\")\ndigits =  re.compile(\"[.]([0-9])\")\n\ndef split_into_sentences(text):\n    \"\"\"\n    This function will be applied to context in df\n    ----------------------------------------------\n    Args: \n        text: str\n    Returns:\n        sentences: List[str]\n    \"\"\"\n    text = \" \" + text + \"  \"\n    text = text.replace(\"\\n\",\" \")\n    text = prefixes.sub(\"\\\\1<prd>\",text)\n    text = websites.sub(\"<prd>\\\\1\",text)\n    text = urls.sub(\"\\\\1<prd>\",text)\n    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n    text = etal.sub(\"\\\\1<prd>\", text)\n    text = digits.sub(\"<prd>\\\\1\",text)\n    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n    text = text.replace(\".\",\".<stop>\")\n    text = text.replace(\"?\",\"?<stop>\")\n    text = text.replace(\"!\",\"!<stop>\")\n    text = text.replace(\"<prd>\",\".\")\n    sentences = text.split(\"<stop>\")\n    if sentences[-1] == '':\n        sentences = sentences[:-1]\n    sentences = [s.strip() for s in sentences]\n    return sentences\n\n\n\ndef clean_text(txt, apply_space_norm=False, strip=False):\n    \"\"\"\n    This function will be applied to question and answer in df\n    ----------------------------------------------------------\n    Args: \n        txt: str\n        apply_space_norm: bool --default False\n        strip: bool --default False\n    Returns:\n        text: str\n    \"\"\"\n    txt = re.sub('\\[[0-9]\\]', '', txt) # remove Wikipedia's quotes\n    if apply_space_norm:\n        txt = re.sub('[^A-Za-z\\u0900-\\u097F\\u0B80-\\u0BFF0-9]+', ' ', str(txt).lower()) # Hindi: \\u0900-\\u097F, Tamil: \\u0B80-\\u0BFF\n    if strip:\n        txt = txt.strip()\n    return txt\n\n\n\ndef shorten_sentences(sentences, max_length=512, overlap=60):\n    \"\"\"\n    If a sentence is longer than `max_length`, break it into chunks of \n    length `max_length` with an overlap of length `overlap`.\n    \n    e.g. if the sentence has 50 tokens, max_length is 20, and overlap is 10.\n    Then the first sentence will be token_i where i in [0,20)\n    Second sentence will be token_i in [10,30).\n    Third sentence [20, 40)\n    Fourth [30, 50)\n    Fifth [40, 60)\n    ------------------------------------------------------------------------\n    Args:\n        sentences: List[str]\n        max_length: int --default 512\n        overlap: int --default 60\n    Returns:\n        shortend_sentences: List[str]\n    \"\"\"\n    shortened_sentences = []\n    for sentence in sentences:\n        sentence = clean_text(sentence, apply_space_norm=True)\n        words = sentence.split()\n        num_words = len(words)\n        if num_words > max_length:\n            for start_index in range(0, num_words, max_length - overlap):\n                shortened_sentences.append(' '.join(words[start_index:start_index+max_length]))\n        else:\n            shortened_sentences.append(sentence)\n    return shortened_sentences\n\n# refenrece:\n# [1] https://stackoverflow.com/questions/41356013/how-to-detect-if-a-string-contains-hindi-devnagri-in-it-with-character-and-wor\n# [2] https://en.wikipedia.org/wiki/Unicode_block\n# [3] https://www.kaggle.com/nbroad/no-training-question-answering-model?scriptVersionId=66240356\n\n\n\n\ndef read_chaii(df):\n    \"\"\"\n    Args:\n        df: pd.DataFrame\n    Returns:\n        contexts: List[str]\n        questions: List[str]\n    \"\"\"\n    contexts = []\n    questions = []\n    ids = []\n    for i,row in df.iterrows():\n        row_context_sentences = row[\"context_sentences\"]\n        row_question = row[\"question\"]\n        row_id = row[\"id\"]\n\n        for context_sentence in row_context_sentences:\n            contexts.append(context_sentence)\n            questions.append(row_question)\n            ids.append(row_id)\n    \n    return contexts, questions, ids\n\n\n\nclass ChaiiDataset(Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\n    def __len__(self):\n        return len(self.encodings.input_ids)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T02:17:33.558221Z","iopub.execute_input":"2021-09-27T02:17:33.558687Z","iopub.status.idle":"2021-09-27T02:17:33.582425Z","shell.execute_reply.started":"2021-09-27T02:17:33.558652Z","shell.execute_reply":"2021-09-27T02:17:33.581713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if USE_PIPELINE:\n    test = test_fn_pipeline()\nelse:\n    test[\"context_sentences\"] = test[\"context\"].apply(clean_text).apply(split_into_sentences).apply(shorten_sentences)\n    test[\"question\"] = test[\"question\"].apply(clean_text, apply_space_norm=True, strip=True)\n    test_contexts, test_questions, test_ids = read_chaii(test)\n    test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True)\n    test_dataset = ChaiiDataset(test_encodings)\n    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n    \n    model.eval()\n    test = pd.DataFrame({\"id\": test_ids, \"context\": test_contexts, \"question\": test_questions})\n    test = test_fn_naive(test, verbose=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T02:17:33.5841Z","iopub.execute_input":"2021-09-27T02:17:33.584508Z","iopub.status.idle":"2021-09-27T02:17:45.483467Z","shell.execute_reply.started":"2021-09-27T02:17:33.584411Z","shell.execute_reply":"2021-09-27T02:17:45.48267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(test.tail(20))","metadata":{"execution":{"iopub.status.busy":"2021-09-27T02:17:45.484757Z","iopub.execute_input":"2021-09-27T02:17:45.485089Z","iopub.status.idle":"2021-09-27T02:17:45.499816Z","shell.execute_reply.started":"2021-09-27T02:17:45.485053Z","shell.execute_reply":"2021-09-27T02:17:45.498804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.dropna(inplace=True)\ntest = test.groupby(\"id\")[\"PredictionString\"].agg(custom_mode).to_frame().reset_index()\ndisplay(test)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T02:18:30.173437Z","iopub.execute_input":"2021-09-27T02:18:30.173809Z","iopub.status.idle":"2021-09-27T02:18:30.188587Z","shell.execute_reply.started":"2021-09-27T02:18:30.173773Z","shell.execute_reply":"2021-09-27T02:18:30.187499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test[[\"id\", \"PredictionString\"]].to_csv(\"submission.csv\", index=False)\ntest.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T02:18:36.319618Z","iopub.execute_input":"2021-09-27T02:18:36.31996Z","iopub.status.idle":"2021-09-27T02:18:36.327504Z","shell.execute_reply.started":"2021-09-27T02:18:36.319929Z","shell.execute_reply":"2021-09-27T02:18:36.326598Z"},"trusted":true},"execution_count":null,"outputs":[]}]}